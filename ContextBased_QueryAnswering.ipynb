{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "\n",
    "import contractions\n",
    "\n",
    "from string import digits\n",
    "\n",
    "import re\n",
    "\n",
    "import pymongo\n",
    "\n",
    "import gensim\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "# import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import os, multiprocessing, time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "    res = str(text).translate(remove_digits)\n",
    "\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    text = strip_html_tags(text)\n",
    "    \n",
    "    cont = [contractions.fix(tok) for tok in text.split()]\n",
    "    \n",
    "    text = ' '.join([word for word in cont if not word.isdigit()])\n",
    "\n",
    "    text = re.sub(' +',' ',res)\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    clean = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    \n",
    "#     stemmer = PorterStemmer()\n",
    "    \n",
    "#     clean = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    \"\"\"remove html tags from text\"\"\"\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text(separator=\" \")\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "db = conn['BDMSEndSem']\n",
    "\n",
    "ques_col = db.get_collection('query_answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_['clean_text'] = clean_text(one_['accepted_answer'])\n",
    "\n",
    "# ques_col.update_one({'_id' : ObjectId(one_['_id'])}, one_ ,upsert = False)\n",
    "\n",
    "# update = {'clean_aa': clean_text(one_['accepted_answer']),\n",
    "#           'clean_qt': clean_text(one_['question_title']),\n",
    "#           'clean_qb': clean_text(one_['question_body']),\n",
    "#           'clean_tg': clean_text(one_['tags'])}\n",
    "\n",
    "\n",
    "# ques_col.update_one(\n",
    "#         {'_id': ObjectId(one_['_id'])},\n",
    "#         { \"$set\":update })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samp = 1000\n",
    "\n",
    "D = ques_col.find({}, no_cursor_timeout=True).limit(n_samp)\n",
    "\n",
    "for i, doc in tqdm(enumerate(D)):\n",
    "    \n",
    "    update = {'clean_aa': clean_text(doc['accepted_answer']),\n",
    "          'clean_qt': clean_text(doc['question_title']),\n",
    "          'clean_qb': clean_text(doc['question_body']),\n",
    "          'clean_tg': clean_text(doc['tags'])}\n",
    "    \n",
    "    ques_col.update_one(\n",
    "        {'_id': ObjectId(doc['_id'])},\n",
    "        { \"$set\":update })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from configparser import ConfigParser\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_frequency = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp = 10000\n",
    "docs = ques_col.find({}, no_cursor_timeout=True).limit(n_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_ =  ques_col.find_one({}, no_cursor_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for doc in docs:\n",
    "    for token in doc['clean_aa'].split(\" \"):\n",
    "        token_frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [ [token for token in doc['clean_aa'].split(\" \") if token_frequency[token] > 1]\n",
    "                for doc in docs  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in documents:\n",
    "#     doc.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('stack_of.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('stack_of.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bow_doc_4310 = corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=100, id2word=dictionary, passes=20, workers=8)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf[corpus[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = 'Applying CSS to Datatables that has NEXT Page'\n",
    "\n",
    "bow_vector = dictionary.doc2bow(clean_text(unseen_document).split(\" \"))\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def clean_text_db(doc):\n",
    "    \n",
    "#     update = {'clean_aa': clean_text(doc['accepted_answer']),\n",
    "#           'clean_qt': clean_text(doc['question_title']),\n",
    "#           'clean_qb': clean_text(doc['question_body']),\n",
    "#           'clean_tg': clean_text(doc['tags'])}\n",
    "        \n",
    "#     ques_col.update_one(\n",
    "#         {'_id': ObjectId(doc['_id'])},\n",
    "#         { \"$set\":update })\n",
    "    \n",
    "#     return 'done'\n",
    "\n",
    "# # from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "# pool = multiprocessing.Pool(8)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# pool.map(clean_text_db, D)\n",
    "\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Time Taken:\",timedelta(seconds=(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# import os\n",
    "\n",
    "# multiprocessing.cpu_count()\n",
    "\n",
    "# import os, multiprocessing, time\n",
    "# from datetime import timedelta\n",
    "# def sum_of_cubes(n):\n",
    "#     return sum(x**3 for x in range(n))\n",
    "\n",
    "# from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "# pool = Pool(8)\n",
    "\n",
    "# start = time.time()\n",
    "# print(pool.map(sum_of_cubes, range(1000, 100000, 1000)))\n",
    "# end = time.time()\n",
    "# print(timedelta(seconds=(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = 'How to add a smooth transition effect'\n",
    "\n",
    "bow_vector = dictionary.doc2bow(clean_text(unseen_document).split(\" \"))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_document(9, topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_data =  gensimvis.prepare(lda_model, bow_corpus, dictionary)\n",
    "pyLDAvis.display(followers_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = None\n",
    "n_out = 7\n",
    "n_weight = 5\n",
    "n_samp=10000\n",
    "n_components    = 10     # Number of dimension for TruncatedSVD\n",
    "n_clusters      = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer  = TfidfVectorizer(max_df=0.9,  min_df=6,\n",
    "                            max_features=500, use_idf=True,\n",
    "                            strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ques_col.find({}, no_cursor_timeout=True).limit(n_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [ [token for token in doc['clean_aa'].split(\" \") if token_frequency[token] > 1]\n",
    "                for doc in docs  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized   = [ ' '.join(doc) for doc in documents ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(tokenized)\n",
    "\n",
    "svd  = TruncatedSVD(n_components, random_state= 10)\n",
    "svdX = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=4,\n",
    "                verbose=False, random_state= 10)\n",
    "km.fit(svdX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " metrics.silhouette_score(svdX, km.labels_, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms   = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(svd.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if topic is None:\n",
    "        for k in range(n_components):\n",
    "            idx = {i:abs(j) for i, j in enumerate(svd.components_[k])}\n",
    "            sorted_idx = sorted(idx.items(), key=operator.itemgetter(1), reverse=True)\n",
    "            weight = np.mean([ item[1] for item in sorted_idx[0:n_weight] ])\n",
    "            print(\"T%s)\" % k, end =' ')\n",
    "            for item in sorted_idx[0:n_out-1]:\n",
    "                print( \" %0.3f*%s\"  % (item[1] , terms[item[0]]) , end=' ')\n",
    "            print()\n",
    "else:\n",
    "        m = max(svd.components_[topic])\n",
    "        idx = {i:abs(j) for i, j in enumerate(svd.components_[topic])}\n",
    "        sorted_idx = sorted(idx.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        weight = np.mean([ item[1] for item in sorted_idx[0:n_weight] ])\n",
    "        print(\"* T %s) weight: %0.2f\" % (topic, weight), end=' ')\n",
    "        for item in sorted_idx[0:n_out-1]:\n",
    "            print( \" %0.3f*%s\"  % (item[1] , terms[item[0]]) , end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(svdX, y_pred, centers):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    f, ax1 = plt.subplots(1, 1, figsize=( 16, 8), facecolor='white')\n",
    "    ax1.set_xlabel(\"\")\n",
    "    ax1.set_ylabel(\"\")\n",
    "    ax1.set_title(\"K-Means\")\n",
    "    # Only plots the first 2 dimensions of the svdX matrix\n",
    "    ax1.scatter(svdX[:,0], svdX[:,1], c=y_pred, cmap=plt.cm.Paired, s=45)\n",
    "    ax1.scatter(centers[:, 0], centers[:, 1], marker='o', c=\"black\", alpha=1, s=150)\n",
    "    ax1.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = km.predict(svdX)\n",
    "centers = km.cluster_centers_\n",
    "\n",
    "plot_clusters(svdX, y_pred, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(\"stack_of.dict\")\n",
    "lda_model=models.LdaModel.load('lda_model.lda')\n",
    "corpus = corpora.MmCorpus(\"stack_of.mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = 'How to add a smooth transition effect'\n",
    "\n",
    "bow_vector = dictionary.doc2bow(clean_text(unseen_document).split(\" \"))\n",
    "\n",
    "vector = lda_model[bow_vector]\n",
    "\n",
    "vector.sort(key=itemgetter(1), reverse=True)\n",
    " \n",
    "all_topics = lda_model.print_topics()\n",
    "\n",
    "docs_per_topic = [[] for _ in all_topics]\n",
    "\n",
    "\n",
    "for doc_id, doc_bow in enumerate(corpus):\n",
    "    # ...get its topics...\n",
    "    doc_topics = lda_model.get_document_topics(doc_bow)\n",
    "    # ...& for each of its topics...\n",
    "    for topic_id, score in doc_topics:\n",
    "        # ...add the doc_id & its score to the topic's doc list\n",
    "        docs_per_topic[topic_id].append((doc_id, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(q_text):\n",
    "    unseen_doc = dictionary.doc2bow(clean_text(q_text).split(\" \"))\n",
    "    vector = lda_model[unseen_doc]\n",
    "    \n",
    "    vector.sort(key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    topic_id = vector[0][0]\n",
    "    \n",
    "    doc_id = docs_per_topic[topic_id][0][0]\n",
    "    \n",
    "    answer = ques_col.find_one({ \"clean_aa\": ' '.join(documents[doc_id])})['accepted_answer']\n",
    "    \n",
    "    return answer\n",
    "get_answer('How to add a smooth transition in HTML with CSS?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    docs_per_topic[i].sort(reverse=True,key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_per_topic[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_lsa(q_text):\n",
    "    unseen_doc=clean_text(q_text).split(\" \")\n",
    "    \n",
    "    new_vec = dictionary.doc2bow(unseen_doc)\n",
    "    vec_bow_tfidf = tfidf[new_vec]\n",
    "    vector = lsi[vec_bow_tfidf]\n",
    "   \n",
    "\n",
    "    vector.sort(key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    topic_id = vector[0][0]\n",
    "    \n",
    "    doc_id = docs_per_topic[topic_id][0][0]\n",
    "    \n",
    "    answer = ques_col.find_one({ \"clean_aa\": ' '.join(documents[doc_id])})['accepted_answer']\n",
    "\n",
    "    return answer\n",
    "get_answer_lsa('How to add a smooth transition in HTML with CSS?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LsiModel(corpus, id2word=dictionary)\n",
    "vectorized_corpus = model[corpus] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus, smartirs='npu')\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = gensim.models.LsiModel(corpus_tfidf, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
